{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SebastianNewberry/BeTheWhirlwind/blob/master/run_ollama_in_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0MJe6AusVtI"
      },
      "source": [
        "## Run Ollama in Colab\n",
        "\n",
        "### Code to initialize llama using Unsloth was retrieved from\n",
        "\n",
        "https://colab.research.google.com/drive/1T5-zKWM_5OD21QHwXHiV9ixTRR7k3iB9?usp=sharing#scrollTo=2eSvM9zX_2d3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install unsloth"
      ],
      "metadata": {
        "id": "3KJQQP3ZvVI5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = False # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 2x faster\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # 4bit for 405b!\n",
        "    \"unsloth/Mistral-Small-Instruct-2409\",     # Mistral 22b 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "\n",
        "    \"unsloth/Llama-3.2-1B-bnb-4bit\",           # NEW! Llama 3.2 models\n",
        "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "\n",
        "    \"unsloth/Llama-3.3-70B-Instruct-bnb-4bit\" # NEW! Llama 3.3 70B!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-3B-Instruct\", # or choose \"unsloth/Llama-3.2-1B-Instruct\"\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-kJWXK4vYy8",
        "outputId": "e8964508-8a29-476d-a5ce-b839a2e0084b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.3.\n",
            "   \\\\   /|    NVIDIA A100-SXM4-40GB. Num GPUs = 1. Max memory: 39.557 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.0. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 1, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ],
      "metadata": {
        "id": "gzxZE8YozcGW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.2\",\n",
        ")\n",
        "\n",
        "def formatting_train_prompts(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(\n",
        "        examples[\"text\"],  # Use only text\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=2048,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "# Load the full dataset\n",
        "full_dataset = load_dataset(\"mlabonne/FineTome-100k\", split=\"train\")\n",
        "\n",
        "# Split the dataset into training and testing sets (e.g., 80% train, 20% test)\n",
        "split_datasets = full_dataset.train_test_split(test_size=0.2, seed=42)\n",
        "\n",
        "# Access the train and test splits\n",
        "train_dataset = split_datasets['train']\n",
        "test_dataset = split_datasets['test']\n",
        "\n",
        "print(f\"Train dataset: {train_dataset}\")\n",
        "print(f\"Test dataset: {test_dataset}\")"
      ],
      "metadata": {
        "id": "WHB254cnJB2t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1dbe3ee-c1d1-447a-ec24-a7d3ea2efd70"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train dataset: Dataset({\n",
            "    features: ['conversations', 'source', 'score'],\n",
            "    num_rows: 80000\n",
            "})\n",
            "Test dataset: Dataset({\n",
            "    features: ['conversations', 'source', 'score'],\n",
            "    num_rows: 20000\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import standardize_sharegpt\n",
        "train_dataset = standardize_sharegpt(train_dataset)\n",
        "train_dataset = train_dataset.map(formatting_train_prompts, batched = True,)\n",
        "test_dataset = standardize_sharegpt(test_dataset)\n",
        "test_dataset = test_dataset.map(formatting_train_prompts, batched=True)\n",
        "tokenized_datasets = test_dataset.map(tokenize_function, batched=True)"
      ],
      "metadata": {
        "id": "L5o4EfODWYmy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "5c915f23310d4d5898c44ff18831821a",
            "c26fd868f17d4518a9d99d24c677307a",
            "31f19d49d4224de08e3b759127ad466d",
            "d07c2008691a4258a2b2d2626ff930eb",
            "a80b012a0628415bbee64de7f5c0cb5c",
            "e09ae238cd604276904f8d3c21ed065e",
            "6ff697328b5b473c94ebd83d209e5290",
            "675c1b2eb3254b738ce2146e4ebb053d",
            "3e2f7d5a36144d4b8b22779243845cc9",
            "ab945cd8a006457494161585e461b83a",
            "1b31d23344ec47918ce30f8d48278552"
          ]
        },
        "outputId": "44fad621-4b47-4580-f6d0-0da322777290"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/20000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c915f23310d4d5898c44ff18831821a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "import torch\n",
        "\n",
        "# Assuming tokenizer and model are already loaded\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template=\"llama-3.2\",\n",
        ")\n",
        "\n",
        "# Define a list of messages (each entry follows the chat template format)\n",
        "\n",
        "# Used ChatGPT to come up with these questions for different tasks regarding text summarization, question answering, text classification, role playing, and reasoning.\n",
        "\n",
        "message_list = [\n",
        "    [{\"role\": \"system\", \"content\": \"You are a helpful AI assistant that specializes in summarizing text.\\n\\n\"}, # Text Summarization\n",
        "     {\"role\": \"user\", \"content\": \"Summarize the following article in 2-3 sentences:\\n\\nIn recent years, the importance of renewable energy has grown significantly due to increasing concerns about climate change. Solar and wind energy are leading the way in the shift towards cleaner energy sources. Governments worldwide are investing heavily in renewable energy technologies, and many countries are setting ambitious goals for reducing carbon emissions. The transition to renewable energy is seen as crucial to mitigating the impacts of climate change and ensuring a sustainable future for generations to come.\\n\\n\"}],\n",
        "\n",
        "    [{\"role\": \"system\", \"content\": \"You are an AI assistant that answers questions based on provided passages.\\n\\n\"}, # Question Answering\n",
        "     {\"role\": \"user\", \"content\": \"Read the following passage and answer the question:\\n\\nThe Eiffel Tower is located in Paris, France. It was completed in 1889 for the World's Fair and was originally intended as a temporary structure. However, it became one of the most iconic landmarks in the world, attracting millions of visitors each year.\\n\\nQuestion: When was the Eiffel Tower completed?\\n\\n\"}],\n",
        "\n",
        "    [{\"role\": \"system\", \"content\": \"You are an AI that classifies text into categories: Technology, Health, Sports, or Politics.\\n\\n\"}, # Text Classification\n",
        "     {\"role\": \"user\", \"content\": \"Classify the following text:\\n\\nThe latest advancements in AI and machine learning are revolutionizing industries. Companies are now using AI to improve efficiency and productivity in various sectors, from healthcare to finance.\\n\\n\"}],\n",
        "\n",
        "    [{\"role\": \"system\", \"content\": \"You are a customer support agent for an online course company. Respond helpfully to customers.\\n\\n\"}, # Role Playing\n",
        "     {\"role\": \"user\", \"content\": \"Hi, I’m having trouble accessing the course I purchased. Can you help me?\\n\\n\"}],\n",
        "\n",
        "    [{\"role\": \"system\", \"content\": \"Answer the following reasoning question:\\n\\n\"}, #Reasoning\n",
        "     {\"role\": \"user\", \"content\": \"If all roses are flowers, and some flowers are red, can we conclude that some roses are red?\\n\\n\"}]\n",
        "]\n",
        "\n",
        "# Store results\n",
        "generated_outputs = []\n",
        "\n",
        "# Iterate through message list and generate responses\n",
        "for messages in message_list:\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,  # Required for generation\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Run inference without gradient tracking\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs,\n",
        "            max_new_tokens=2048,\n",
        "            use_cache=True,\n",
        "            temperature=1.5,\n",
        "            min_p=0.1\n",
        "        )\n",
        "\n",
        "    # Decode and store the output\n",
        "    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    generated_outputs.append(output_text)\n",
        "\n",
        "prompt_types = [\"Text Summarization\", \"Question Answering\", \"Text Classification\", \"Role Playing\", \"Reasoning\"]\n",
        "\n",
        "# Print all generated responses\n",
        "for response, prompt_type in zip(generated_outputs, prompt_types):\n",
        "    print(f\"Prompt Type: {prompt_type}\\n\\n\")\n",
        "\n",
        "    print(f\"Response: {response}\\n\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2y990-s8batG",
        "outputId": "201b0c1f-169d-40ac-a34b-dbfcca2951c0"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt Type: Text Summarization\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are a helpful AI assistant that specializes in summarizing text.\n",
            "\n",
            "user\n",
            "\n",
            "Summarize the following article in 2-3 sentences:\n",
            "\n",
            "In recent years, the importance of renewable energy has grown significantly due to increasing concerns about climate change. Solar and wind energy are leading the way in the shift towards cleaner energy sources. Governments worldwide are investing heavily in renewable energy technologies, and many countries are setting ambitious goals for reducing carbon emissions. The transition to renewable energy is seen as crucial to mitigating the impacts of climate change and ensuring a sustainable future for generations to come.\n",
            "\n",
            "assistant\n",
            "\n",
            "Here is a 2-3 sentence summary of the article:\n",
            "\n",
            "The importance of renewable energy has significantly grown due to climate change concerns. Solar and wind energy are at the forefront of the shift towards cleaner energy sources, with governments worldwide investing heavily in this field. The transition to renewable energy is crucial for mitigating climate change and securing a sustainable future.\n",
            "\n",
            "\n",
            "\n",
            "Prompt Type: Question Answering\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an AI assistant that answers questions based on provided passages.\n",
            "\n",
            "user\n",
            "\n",
            "Read the following passage and answer the question:\n",
            "\n",
            "The Eiffel Tower is located in Paris, France. It was completed in 1889 for the World's Fair and was originally intended as a temporary structure. However, it became one of the most iconic landmarks in the world, attracting millions of visitors each year.\n",
            "\n",
            "Question: When was the Eiffel Tower completed?\n",
            "\n",
            "assistant\n",
            "\n",
            "According to the passage, the Eiffel Tower was completed in 1889.\n",
            "\n",
            "\n",
            "\n",
            "Prompt Type: Text Classification\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an AI that classifies text into categories: Technology, Health, Sports, or Politics.\n",
            "\n",
            "user\n",
            "\n",
            "Classify the following text:\n",
            "\n",
            "The latest advancements in AI and machine learning are revolutionizing industries. Companies are now using AI to improve efficiency and productivity in various sectors, from healthcare to finance.\n",
            "\n",
            "assistant\n",
            "\n",
            "I would classify the text as: Technology\n",
            "\n",
            "\n",
            "\n",
            "Prompt Type: Role Playing\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are a customer support agent for an online course company. Respond helpfully to customers.\n",
            "\n",
            "user\n",
            "\n",
            "Hi, I’m having trouble accessing the course I purchased. Can you help me?\n",
            "\n",
            "assistant\n",
            "\n",
            "I'd be happy to help you access the course. Can you please provide me with some more details so I can assist you better? \n",
            "\n",
            "Here are a few questions to get started:\n",
            "\n",
            "- What is your course name?\n",
            "- What browser and device are you using to access the course?\n",
            "- Have you tried logging in to the course using the email address and password associated with your purchase?\n",
            "- If you're trying to access the course through a subscription plan, please note that it may take 24 hours for new courses to become available in your library.\n",
            "\n",
            "If you have already tried the above, we can further troubleshoot together to resolve any issues and get you access to the course.\n",
            "\n",
            "\n",
            "\n",
            "Prompt Type: Reasoning\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "Answer the following reasoning question:\n",
            "\n",
            "user\n",
            "\n",
            "If all roses are flowers, and some flowers are red, can we conclude that some roses are red?\n",
            "\n",
            "assistant\n",
            "\n",
            "No, we cannot conclude that some roses are red. \n",
            "\n",
            "The information given is:\n",
            "1. All roses are flowers. (A)\n",
            "2. Some flowers are red. (B)\n",
            "\n",
            "However, the conclusion we can draw is that all flowers are red that are roses, or rather, the flowers that are roses are the same flowers that are red (B is true for some roses in set A), but it does not mean that some roses are red.\n",
            "\n",
            "For a valid conclusion to be drawn from B, we would need another statement linking flowers and roses that are red directly, not just general information that roses and flowers are both flowers.\n",
            "\n",
            "We could say the set of 'roses' is a subset of the set 'flowers' (A), and since some flowers are red (B), it means that at least some 'roses' are red because roses are a subset of flowers and the properties of roses being part of the flowers subset implies they can be classified under 'flowers' that are red.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model performance on the representative dataset before training"
      ],
      "metadata": {
        "id": "Ez37R6nEnp5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages_list = [[{\"role\": conv[\"role\"], \"content\": conv[\"content\"] + \"\\n\\n\"} for conv in message] for message in test_dataset[\"conversations\"][:5]] # test the first 5 samples of the representative dataset that will be trained\n",
        "\n",
        "# Store results\n",
        "generated_outputs = []\n",
        "\n",
        "# Iterate through message list and generate responses\n",
        "for messages in messages_list:\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,  # Required for generation\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Run inference without gradient tracking\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs,\n",
        "            max_new_tokens=2048,\n",
        "            use_cache=True,\n",
        "            temperature=1.5,\n",
        "            min_p=0.1\n",
        "        )\n",
        "\n",
        "    # Decode and store the output\n",
        "    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    generated_outputs.append(output_text)\n",
        "\n",
        "for response in generated_outputs:\n",
        "    print(f\"Response: {response}\\n\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYlBbXFZnpbN",
        "outputId": "786c2e5c-fc5e-497e-ae03-dbf68d17cb3e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "Give three types of computer graphics.\n",
            "\n",
            "assistant\n",
            "\n",
            "1. Raster Graphics: These are also called bitmap graphics and are composed of pixels arranged in a grid. Each pixel can have a different color and shade. Raster graphics excel at representing photographic images and digital painting.\n",
            "\n",
            "2. Vector Graphics: These graphics are constructed using mathematical formulas representing geometric shapes like lines, curves, and polygons. They are resolution-independent, meaning they can be scaled up or down in size without losing quality. Vector graphics are commonly used for logos, icons, typography and illustrations.\n",
            "\n",
            "3. 3D Graphics: These graphics are used to create three-dimensional digital representations of objects. 3D graphics use techniques like modeling, rendering, and shading to simulate depth and surface properties. These graphics are used in animation, video games, architecture, engineering, and virtual reality.\n",
            "\n",
            "assistant\n",
            "\n",
            "I can provide a more detailed explanation of the three types of computer graphics I mentioned earlier. Here's an expanded version:\n",
            "\n",
            "1. Raster Graphics:\n",
            "   - Also known as bitmap graphics, raster graphics are composed of pixels arranged in a grid.\n",
            "   - Each pixel can have a different color and shade, making it ideal for representing photographic images and digital painting.\n",
            "   - However, raster graphics are not suitable for scalable images and may degrade in quality when enlarged.\n",
            "\n",
            "2. Vector Graphics:\n",
            "   - Constructed using mathematical formulas representing geometric shapes like lines, curves, and polygons.\n",
            "   - Vector graphics are resolution-independent, meaning they can be scaled up or down in size without losing quality.\n",
            "   - This property makes them suitable for use in logos, icons, typography, and illustrations where precise scaling is required.\n",
            "\n",
            "3. 3D Graphics:\n",
            "   - Create three-dimensional digital representations of objects.\n",
            "   - Techniques like modeling, rendering, and shading are used to simulate depth and surface properties.\n",
            "   - 3D graphics are widely used in animation, video games, architecture, engineering, and virtual reality applications where immersive experiences are essential.\n",
            "\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "Write Python code to solve the task:\n",
            "Let S be the concatenation of 10^{10} copies of the string 110. (For reference, the concatenation of 3 copies of 110 is 110110110.)\n",
            "We have a string T of length N.\n",
            "Find the number of times T occurs in S as a contiguous substring.\n",
            "\n",
            "-----Constraints-----\n",
            " - 1 \\leq N \\leq 2 \\times 10^5\n",
            " - T is a string of length N consisting of 0 and 1.\n",
            "\n",
            "-----Input-----\n",
            "Input is given from Standard Input in the following format:\n",
            "N\n",
            "T\n",
            "\n",
            "-----Output-----\n",
            "Print the number of times T occurs in S as a contiguous substring.\n",
            "\n",
            "-----Sample Input-----\n",
            "4\n",
            "1011\n",
            "\n",
            "-----Sample Output-----\n",
            "9999999999\n",
            "\n",
            "S is so long, so let us instead count the number of times 1011 occurs in the concatenation of 3 copies of 110, that is, 110110110. We can see it occurs twice:\n",
            " - 1 1011 0110\n",
            " - 1101 1011 0\n",
            "\n",
            "assistant\n",
            "\n",
            "Step 1:  The problem requires finding the number of times a string T occurs as a contiguous substring in a very long string S.\n",
            "Step 2:  Since we are given the pattern and the length of T, we can use the occurrences of T in a shorter pattern to simplify the counting.\n",
            "Step 3:  We can identify edge cases by checking if T contains '00' or '111' and handle them accordingly.\n",
            "Step 4:  For the cases where '00', '111', or '010' is present in T, the number of occurrences is 0.\n",
            "Step 5:  If the last character of T is '1', then the number of occurrences is 10^10 - the count of '0' in T. Otherwise, it's 10^10 - the count of '0' in T plus 1.\n",
            "```python\n",
            "# Step 6:  Initialize the length of the input string.\n",
            "n = int(input())\n",
            "# Step 7:  Read the input string.\n",
            "t = input()\n",
            "# Step 8:  Check if the input string corresponds to specific cases and print the result accordingly.\n",
            "if t == '1':\n",
            "    print(10 ** 10 * 2)\n",
            "elif t == '11':\n",
            "    print(10 ** 10)\n",
            "elif '00' in t or '111' in t or '010' in t:\n",
            "    print(0)\n",
            "else:\n",
            "    # Step 9:  Count the occurrences of '0' in the input string.\n",
            "    \n",
            "    a = t.count('0')\n",
            "    # Step 10:  Print the number of times T occurs in S as a contiguous substring based on specific conditions.\n",
            "    \n",
            "    if t[-1] == '1':\n",
            "        print(10 ** 10 - a)\n",
            "    else:\n",
            "        print(10 ** 10 - a + 1)\n",
            "\n",
            "```\n",
            "\n",
            "assistant\n",
            "\n",
            "The code you have written is almost correct. Here's the refactored and improved version of your code:\n",
            "\n",
            "```python\n",
            "def count_occurrences(n, t):\n",
            "    \"\"\"\n",
            "    This function calculates the number of times the string T occurs in S as a contiguous substring.\n",
            "    \n",
            "    Args:\n",
            "    n (int): The length of the string S.\n",
            "    t (str): The string to be searched in S.\n",
            "    \n",
            "    Returns:\n",
            "    int: The number of occurrences of T in S.\n",
            "    \"\"\"\n",
            "\n",
            "    # If the string contains '00', '111', or '010', return 0\n",
            "    if '00' in t or '111' in t or '010' in t:\n",
            "        return 0\n",
            "    \n",
            "    # Calculate the count of '0' in the input string\n",
            "    zeros = t.count('0')\n",
            "    \n",
            "    # If the last character of the input string is '1', calculate the number of occurrences\n",
            "    if t[-1] == '1':\n",
            "        return (10 ** 10 - zeros) * (10 ** n - 1)\n",
            "    # Otherwise, subtract the zeros from 10^10 and add 1\n",
            "    else:\n",
            "        return (10 ** 10 - zeros)\n",
            "\n",
            "\n",
            "n = int(input())\n",
            "t = input()\n",
            "result = count_occurrences(n, t)\n",
            "print(result)\n",
            "```\n",
            "The changes made were:\n",
            "*   Factored out the logic into a function to improve readability.\n",
            "*   Added a docstring to describe the function and its parameters.\n",
            "*   Removed redundant comments and rephrased comments to be more concise and clear.\n",
            "*   Renamed `a` variable to `zeros` for better understanding.\n",
            "*   Added a blank line after the docstring for readability.\n",
            "*   Used consistent spacing throughout the code.\n",
            "*   Removed unnecessary type conversion of `n` to `int`.\n",
            "\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "Can you provide information on the most effective methods for teaching language to young children?\n",
            "\n",
            "assistant\n",
            "\n",
            "As an AI language model, I can provide you with some information on effective methods of teaching language to young children:\n",
            "\n",
            "1. Immersion: Immersing children in the language they are trying to learn is an effective way to teach them a language. Children can be taught through games, songs, books, stories, and other fun activities that make learning an enjoyable experience.\n",
            "\n",
            "2. Repetition: Repetition is essential for children to learn a language. Repetitive words, phrases, and sentences help children remember and understand the language better.\n",
            "\n",
            "3. Total physical response (TPR): Total physical response (TPR) is a method of teaching a language that involves physical movement. Children respond to verbal commands with physical actions that correspond to the language. This method helps children to remember vocabulary and grammar easily.\n",
            "\n",
            "4. Storytelling: Young children are fascinated by stories. Incorporating storytelling into language teaching can help to increase their language skills. Telling stories helps to build vocabulary, grammar, and comprehension.\n",
            "\n",
            "5. Learning through play: Play is an excellent way to build language among young children. Children explore the world around them through play and learn new words, concepts, and ideas through these experiences.\n",
            "\n",
            "6. Use of multimedia: Multimodal language teaching includes videos, songs, images, and other multimedia resources in the teaching process. Multimedia teaching can supplement traditional instructional methods and can be used to provide more interactive and engaging learning experiences.\n",
            "\n",
            "7. Parental involvement: Parental involvement plays a significant role in supporting children's language development. Children learn better when parents speak to them in the target language and encourage them to speak and ask questions.\n",
            "\n",
            "user\n",
            "\n",
            "I'll definitely try incorporating more play and storytelling into my language teaching with young children. Do you have any favorite songs or games that work well for teaching language?\n",
            "\n",
            "assistant\n",
            "\n",
            "As an AI language model, I do not have personal preferences, but here are some popular songs and games that are effective at teaching language to young children:\n",
            "\n",
            "1. \"Head, Shoulders, Knees, and Toes\" - This song helps children learn body parts, and it's easy to sing and do the corresponding actions. 2. \"The Wheels on the Bus\" - This song is particularly helpful for teaching vocabulary related to transportation and traveling, such as bus, wheels, horn, and wipers. 3. \"Simon Says\" - This game helps children learn simple commands and body parts, such as \"touch your nose\" or \"jump up and down.\" 4. \"Memory\" - This game involves matching pictures, words, or objects together, which can help children learn vocabulary. 5. \"Red Light, Green Light\" - This game involves physical movement and following directions, which can help children learn verbs and prepositions. 6. \"I Spy\" - This game helps children learn adjectives and practice describing objects, such as \"I spy with my little eye something blue.\" In general, songs and games that involve physical activity, repetition, and the use of fun props or visual aids are most effective at teaching language to young children.\n",
            "\n",
            "user\n",
            "\n",
            "Do you have any recommendations for incorporating technology into language teaching for young children?\n",
            "\n",
            "assistant\n",
            "\n",
            "Certainly! Here are some ways to incorporate technology into language teaching for young children:\n",
            "\n",
            "1. Interactive Apps: There are many fun and interactive language learning apps available, specifically designed for young children. These apps use colorful graphics, animations, and characters, to make learning engaging and fun. 2. Digital storybooks: Digital storybooks with interactive features, such as animations, sounds, and videos, can be a fun way to teach children about new words, grammar, and sentence structures. 3. Online videos: Online videos, such as YouTube or educational websites, can be used to teach children vocabulary, grammar, and pronunciation. There are many videos available specifically designed to teach children, with colorful characters and engaging animations. 4. Virtual Tutoring Sessions: Some language learning platforms offer virtual tutoring sessions with native-speaking teachers, which can be useful for young children who need more structured and personalized language learning. 5. Language Learning Games: There are many language learning games available online that children can play, such as spelling games or word puzzles. These games help children reinforce their language skills while having fun. When incorporating technology into language teaching for young children, it's important to make sure that the content is age-appropriate, engaging, and educational. Additionally, young children should always be supervised when using technology.\n",
            "\n",
            "user\n",
            "\n",
            "I'll definitely look into using some of these tech tools for language teaching. Do you know of any apps or online resources that are particularly effective for teaching pronunciation?\n",
            "\n",
            "assistant\n",
            "\n",
            "Certainly! Here are some apps and online resources that are effective for teaching pronunciation:\n",
            "\n",
            "1. Tongue Twister App: This app is designed to help improve pronunciation and fluency. It includes a broad range of tongue twisters, which can be practiced out loud. 2. Speech Tutor App: Speech Tutor is an app that helps users perfect their pronunciation, by allowing them to see their mouth movements in real-time. The app uses a video component, which requires users to follow along and repeat the sounds made by native speakers. 3. Duolingo: Duolingo is a language learning app that also includes a speech recognition feature, which enables users to practice their pronunciation by speaking into their device's microphone. The app's speech recognition tool provides feedback on pronunciation accuracy and offers suggestions for improvement. 4. Forvo: Forvo is a website that offers pronunciation help, giving users access to an extensive database of sound recordings made by native speakers from around the world. 5. ELSA Speak: ELSA Speak is an AI-powered app specifically designed to improve English language pronunciation. The app uses speech recognition technology to analyze user's speech and provides customized exercises targeted at their pronunciation needs. When using these resources to teach pronunciation to young learners, it's essential to monitor their usage and provide additional support and feedback as needed. It can also be helpful to encourage students to practice their pronunciation in groups or with native speakers, as this can help build their confidence and fluency.\n",
            "\n",
            "user\n",
            "\n",
            "These recommendations are great! I'm excited to try out some of these apps with my students. Have you seen any improvement in language learning outcomes with the use of technology?\n",
            "\n",
            "assistant\n",
            "\n",
            "Yes! The incorporation of technology in language teaching has shown to produce positive outcomes in language learning. Here are some examples:\n",
            "\n",
            "1. Increased motivation: Technology can help to make language learning more fun and engaging for students, which can increase their motivation to learn.\n",
            "\n",
            "2. More interactive and personalized learning experiences: Online resources, such as apps and websites, offer interactive and personalized learning experiences that can be tailored to individual student needs.\n",
            "\n",
            "3. Enhanced learning opportunities: Technology can provide students with access to a variety of resources that may not be available in traditional classroom settings, such as podcasts, videos, and interactive games.\n",
            "\n",
            "4. Improved language fluency: By providing students with opportunities to practice speaking, listening, and writing in different contexts, technology can help improve their fluency in the language.\n",
            "\n",
            "5. Increased accessibility: Technology can increase accessibility to language learning for students who may not have access to traditional classroom settings, such as those who live in rural areas or have physical disabilities.\n",
            "\n",
            "Technology is not a replacement for traditional language teaching methods, but it can be a valuable supplement to help support and enhance the learning process.\n",
            "\n",
            "assistant\n",
            "\n",
            "In terms of specific numbers, a study by the National Center for Education Statistics found that students who used digital resources to learn a language had significantly higher English proficiency scores than those who did not use digital resources.\n",
            "\n",
            "Another study by the National Institute of Standards and Technology found that students who used online language learning tools had a 12% higher language proficiency score than those who did not use online tools.\n",
            "\n",
            "It's also worth noting that the use of technology in language learning has been shown to be particularly effective in increasing student engagement and motivation. A study by the Organization for Economic Co-operation and Development found that students who used digital tools to learn a language were more likely to report feeling engaged and motivated than those who did not use digital tools.\n",
            "\n",
            "Overall, the use of technology in language learning has the potential to produce significant improvements in student outcomes, but it is also important to consider the potential limitations and challenges of using technology in the classroom.\n",
            "\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "How do you solve and graph the compound inequality 2t + 1 > 13 or –18 > 7t + 3?\n",
            "\n",
            "assistant\n",
            "\n",
            "To solve the compound inequality, we need to solve each inequality separately and then combine the solutions.\n",
            "\n",
            "First, let's solve the inequality 2t + 1 > 13.\n",
            "2t + 1 > 13\n",
            "2t > 12\n",
            "t > 6\n",
            "\n",
            "Next, let's solve the inequality –18 > 7t + 3.\n",
            "–18 > 7t + 3\n",
            "–21 > 7t\n",
            "–3 > t\n",
            "\n",
            "Now, we can combine the solutions of the two inequalities. Since the original inequality is connected by \"or\", we need to find the values of t that satisfy either inequality.\n",
            "\n",
            "Therefore, the solution to the compound inequality is t > 6 or t < -3.\n",
            "\n",
            "To graph the solution, we can draw a number line and mark the points t = 6 and t = -3. Then, we shade the regions of the number line that satisfy the inequality.\n",
            "\n",
            "The graph of the solution is shown below:\n",
            "\n",
            "[Image of a number line with points t = 6 and t = -3 marked. The region to the right of t = 6 and the region to the left of t = -3 are shaded.]\n",
            "\n",
            "assistant\n",
            "\n",
            "I can describe the graph further for clarity.\n",
            "\n",
            "On the number line, the line marking t = 6 is dashed, and to the right of it, we shade the entire region until it meets the upper boundary of the line.\n",
            "\n",
            "The line marking t = -3 is also dashed, and to the left of it, we also shade the entire region until it meets the lower boundary of the line.\n",
            "\n",
            "However, because we are only dealing with an 'or' condition, it means t cannot be within the overlap, hence the two regions on either side of -3 do not overlap.\n",
            "\n",
            "Therefore, the final shaded graph displays the areas from both the t > 6 and t < -3 shaded in order, which is -3 at the bottom to t < infinity and 6 at the top to t > infinity\n",
            "\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "What does it mean when we say \"Let $x$ be an element of the set $\\mathbb{R}$\"? Does $x$ represent only a single element of the set $\\mathbb{R}$? Or does $x$ represent all the elements of the set $\\mathbb{R}$ simultaneously at the same time? Some people say that if $x \\in \\mathbb{R}$ then $x$ is any real number; that means $x$ represents all real numbers. But if $x$ is any real number, then let's say $x = 1$; so $x$ is one, then how can it represent all real numbers? Please help me, I am very confused.\n",
            "\n",
            "assistant\n",
            "\n",
            "When we say \"Let $x$ be an element of the set $\\mathbb{R}$\", we mean that $x$ is a variable that can take on any value in the set of real numbers. It does not mean that $x$ represents all real numbers simultaneously.\n",
            "\n",
            "For example, if we say \"Let $x$ be an element of the set $\\mathbb{R}$ and $x^2 = 4$\", then $x$ can be either 2 or -2. It cannot be both 2 and -2 at the same time.\n",
            "\n",
            "The statement \"if $x \\in \\mathbb{R}$ then $x$ is any real number\" is a bit misleading. It is more accurate to say that \"if $x \\in \\mathbb{R}$, then $x$ can be any real number.\"\n",
            "\n",
            "The reason for this confusion is that the symbol \"$x$\" is used in two different ways. Sometimes, it is used to represent a specific real number. For example, if we say \"$x = 1$\", then $x$ represents the specific real number 1. Other times, it is used to represent a variable that can take on any value in a given set. For example, if we say \"Let $x$ be an element of the set $\\mathbb{R}$\", then $x$ is a variable that can take on any value in the set of real numbers.\n",
            "\n",
            "It is important to be aware of this distinction to avoid confusion.\n",
            "\n",
            "assistant\n",
            "\n",
            "To illustrate the difference:\n",
            "\n",
            "* When we say \"$x$ is the number of apples in the basket\", $x$ represents a specific quantity, namely the number of apples.\n",
            "* When we say \"Let $x$ be the variable for the number of apples in the basket\", $x$ can take on any value, including 0, 1, 2, and so on.\n",
            "\n",
            "In the first statement, $x$ is a fixed value that represents a specific quantity. In the second statement, $x$ is a variable that can change value.\n",
            "\n",
            "This distinction is important to make when working with variables, as it can help prevent confusion when reading and writing mathematical statements.\n",
            "\n",
            "In the case of your original question, the correct way to express the idea would be: \"The statement $x = 1$ means that $x$ is a specific real number, whereas the statement $x \\in \\mathbb{R}$ means that $x$ can be any real number.\"\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning using LORA and SFTTrainer which is a special trainer designed to fine-tune models."
      ],
      "metadata": {
        "id": "ZYF6A_tTFwrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "max_seq_length = 2048\n",
        "dtype = None  # Auto detection, change if needed\n",
        "load_in_4bit = False  # Set to True if using 4bit quantization\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_dataset,\n",
        "    dataset_text_field = \"text\",  # Keep this as \"text\" since that's what formatting_func returns\n",
        "    max_seq_length = max_seq_length,\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        learning_rate = 9e-4,\n",
        "        max_steps=60,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0OJDFB0eD4e",
        "outputId": "f6d9d299-a87f-4528-f28f-892b6a0d8219"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: We found double BOS tokens - we shall remove one automatically.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming you already have the model, test_dataset, and trainer set up\n",
        "\n",
        "# Calculate the test loss before training\n",
        "trainer.model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "before_training_results = trainer.evaluate(tokenized_datasets.select(range(200)))\n",
        "print(before_training_results)\n",
        "before_training_loss = before_training_results[\"eval_loss\"]\n",
        "\n",
        "print(train_dataset.column_names)\n",
        "# Train the model\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# Calculate the test loss after training\n",
        "trainer.model.eval()  # Set the model back to evaluation mode\n",
        "after_training_results = trainer.evaluate(tokenized_datasets.select(range(200)))\n",
        "after_training_loss = after_training_results[\"eval_loss\"]\n",
        "\n",
        "# Prepare the data for the bar plot\n",
        "losses = [before_training_loss, after_training_loss]\n",
        "labels = ['Before Training', 'After Training']\n",
        "\n",
        "# Create the bar plot\n",
        "plt.bar(labels, losses, color=['blue', 'green'])\n",
        "plt.xlabel('Stage')\n",
        "plt.ylabel('Test Loss')\n",
        "plt.title('Test Loss Before and After Training')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dqy06i9_uCjt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "outputId": "fa411ef7-01d3-45b0-c609-11a6e7ac16d2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='131' max='25' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [25/25 11:49]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3d7491363d28>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Set the model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mbefore_training_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized_datasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbefore_training_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mbefore_training_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbefore_training_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"eval_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4072\u001b[0m         \u001b[0meval_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_loop\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_legacy_prediction_loop\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation_loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4073\u001b[0;31m         output = eval_loop(\n\u001b[0m\u001b[1;32m   4074\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4075\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4266\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4267\u001b[0;31m             \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4268\u001b[0m             \u001b[0mmain_input_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"main_input_name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4269\u001b[0m             inputs_decode = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m   4481\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mloss_without_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4482\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4483\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4484\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/unsloth_compiled_cache/UnslothSFTTrainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m    745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m         outputs = super().compute_loss(\n\u001b[0m\u001b[1;32m    748\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/_utils.py\u001b[0m in \u001b[0;36m_unsloth_pre_compute_loss\u001b[0;34m(self, model, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0mautocaster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mautocaster\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1025\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_old_compute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1026\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[1;32m   3729\u001b[0m                 \u001b[0mloss_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3730\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mloss_kwargs\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3731\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3732\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3733\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;31m# To act like a decorator so that it can be popped when doing `extract_model_from_parallel`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/accelerate/utils/operations.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconvert_to_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getstate__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_autocast\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mautocast_instance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mdecorate_autocast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__script_unsupported\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"@autocast() decorator is not supported in script mode\"\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_compile.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dynamo_disable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdisable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_dynamo/eval_frame.py\u001b[0m in \u001b[0;36m_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m             )\n\u001b[1;32m    744\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m                 \u001b[0m_maybe_set_eval_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36mPeftModelForCausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict, task_ids, num_logits_to_keep, logits_to_keep, **kwargs)\u001b[0m\n\u001b[1;32m   1206\u001b[0m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1207\u001b[0m ):\n\u001b[0;32m-> 1208\u001b[0;31m     return self.base_model(\n\u001b[0m\u001b[1;32m   1209\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m         \u001b[0mcausal_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcausal_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_injection_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mPeftConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madapter_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth/models/llama.py\u001b[0m in \u001b[0;36m_CausalLM_fast_forward\u001b[0;34m(self, input_ids, causal_mask, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, num_logits_to_keep, logits_to_keep, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m                 \u001b[0mn_items\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"num_items_in_batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"n_items\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m                 loss = fused_linear_cross_entropy(\n\u001b[0m\u001b[1;32m   1099\u001b[0m                     \u001b[0mhidden_states\u001b[0m      \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mlm_weight\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0mlm_head\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/unsloth_zoo/loss_utils.py\u001b[0m in \u001b[0;36mfused_linear_cross_entropy\u001b[0;34m(hidden_states, lm_weight, labels, num_items_in_batch, ignore_index, reduction, logit_softcapping, accuracy_threshold)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"sum\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnum_items_in_batch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"mean\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlogit_softcapping\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlogit_softcapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     loss = linear_cross_entropy(\n\u001b[0m\u001b[1;32m    171\u001b[0m         \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0mlm_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cut_cross_entropy/linear_cross_entropy.py\u001b[0m in \u001b[0;36mlinear_cross_entropy\u001b[0;34m(e, c, targets, ignore_index, softcap, reduction, shift, filter_eps, impl)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mcce_linear_cross_entropy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             return cce_linear_cross_entropy(\n\u001b[0m\u001b[1;32m     59\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftcap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_eps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cut_cross_entropy/cce.py\u001b[0m in \u001b[0;36mcce_linear_cross_entropy\u001b[0;34m(e, c, targets, ignore_index, softcap, reduction, shift, filter_eps)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0mvalids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_flat_valids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cut_cross_entropy/utils.py\u001b[0m in \u001b[0;36m_build_flat_valids\u001b[0;34m(targets, ignore_index, shift)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mvalids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshift\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model performance on representative examples from the dataset after training"
      ],
      "metadata": {
        "id": "GuakVklinKeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages_list = [[{\"role\": conv[\"role\"], \"content\": conv[\"content\"] + \"\\n\\n\"} for conv in message] for message in test_dataset[\"conversations\"][:5]] # test the first 5 samples of the representative dataset that will be trained\n",
        "\n",
        "# Store results\n",
        "generated_outputs = []\n",
        "\n",
        "# Iterate through message list and generate responses\n",
        "for messages in messages_list:\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,  # Required for generation\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Run inference without gradient tracking\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs,\n",
        "            max_new_tokens=2048,\n",
        "            use_cache=True,\n",
        "            temperature=1.5,\n",
        "            min_p=0.1\n",
        "        )\n",
        "\n",
        "    # Decode and store the output\n",
        "    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    generated_outputs.append(output_text)\n",
        "\n",
        "for response in generated_outputs:\n",
        "    print(f\"Response: {response}\\n\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8QCkerXnJRU",
        "outputId": "1d9e0dbd-af42-4718-cff8-4bd5eff972e6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "Give three types of computer graphics.\n",
            "\n",
            "assistant\n",
            "\n",
            "1. Raster Graphics: These are also called bitmap graphics and are composed of pixels arranged in a grid. Each pixel can have a different color and shade. Raster graphics excel at representing photographic images and digital painting.\n",
            "\n",
            "2. Vector Graphics: These graphics are constructed using mathematical formulas representing geometric shapes like lines, curves, and polygons. They are resolution-independent, meaning they can be scaled up or down in size without losing quality. Vector graphics are commonly used for logos, icons, typography and illustrations.\n",
            "\n",
            "3. 3D Graphics: These graphics are used to create three-dimensional digital representations of objects. 3D graphics use techniques like modeling, rendering, and shading to simulate depth and surface properties. These graphics are used in animation, video games, architecture, engineering, and virtual reality.\n",
            "\n",
            "assistant\n",
            "\n",
            "These are three types of computer graphics.\n",
            "\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "Write Python code to solve the task:\n",
            "Let S be the concatenation of 10^{10} copies of the string 110. (For reference, the concatenation of 3 copies of 110 is 110110110.)\n",
            "We have a string T of length N.\n",
            "Find the number of times T occurs in S as a contiguous substring.\n",
            "\n",
            "-----Constraints-----\n",
            " - 1 \\leq N \\leq 2 \\times 10^5\n",
            " - T is a string of length N consisting of 0 and 1.\n",
            "\n",
            "-----Input-----\n",
            "Input is given from Standard Input in the following format:\n",
            "N\n",
            "T\n",
            "\n",
            "-----Output-----\n",
            "Print the number of times T occurs in S as a contiguous substring.\n",
            "\n",
            "-----Sample Input-----\n",
            "4\n",
            "1011\n",
            "\n",
            "-----Sample Output-----\n",
            "9999999999\n",
            "\n",
            "S is so long, so let us instead count the number of times 1011 occurs in the concatenation of 3 copies of 110, that is, 110110110. We can see it occurs twice:\n",
            " - 1 1011 0110\n",
            " - 1101 1011 0\n",
            "\n",
            "assistant\n",
            "\n",
            "Step 1:  The problem requires finding the number of times a string T occurs as a contiguous substring in a very long string S.\n",
            "Step 2:  Since we are given the pattern and the length of T, we can use the occurrences of T in a shorter pattern to simplify the counting.\n",
            "Step 3:  We can identify edge cases by checking if T contains '00' or '111' and handle them accordingly.\n",
            "Step 4:  For the cases where '00', '111', or '010' is present in T, the number of occurrences is 0.\n",
            "Step 5:  If the last character of T is '1', then the number of occurrences is 10^10 - the count of '0' in T. Otherwise, it's 10^10 - the count of '0' in T plus 1.\n",
            "```python\n",
            "# Step 6:  Initialize the length of the input string.\n",
            "n = int(input())\n",
            "# Step 7:  Read the input string.\n",
            "t = input()\n",
            "# Step 8:  Check if the input string corresponds to specific cases and print the result accordingly.\n",
            "if t == '1':\n",
            "    print(10 ** 10 * 2)\n",
            "elif t == '11':\n",
            "    print(10 ** 10)\n",
            "elif '00' in t or '111' in t or '010' in t:\n",
            "    print(0)\n",
            "else:\n",
            "    # Step 9:  Count the occurrences of '0' in the input string.\n",
            "    \n",
            "    a = t.count('0')\n",
            "    # Step 10:  Print the number of times T occurs in S as a contiguous substring based on specific conditions.\n",
            "    \n",
            "    if t[-1] == '1':\n",
            "        print(10 ** 10 - a)\n",
            "    else:\n",
            "        print(10 ** 10 - a + 1)\n",
            "\n",
            "```\n",
            "\n",
            "assistant\n",
            "\n",
            "Step 1:  The problem requires finding the number of times a string T occurs as a contiguous substring in a very long string S.\n",
            "Step 2:  Since we are given the pattern and the length of T, we can use the occurrences of T in a shorter pattern to simplify the counting.\n",
            "Step 3:  We can identify edge cases by checking if T contains '00' or '111' and handle them accordingly.\n",
            "Step 4:  For the cases where '00', '111', or '010' is present in T, the number of occurrences is 0.\n",
            "Step 5:  If the last character of T is '1', then the number of occurrences is 10^10 - the count of '0' in T. Otherwise, it's 10^10 - the count of '0' in T plus 1.\n",
            "\n",
            "```python\n",
            "# Step 6:  Initialize the length of the input string.\n",
            "n = int(input())\n",
            "# Step 7:  Read the input string.\n",
            "t = input()\n",
            "# Step 8:  Check if the input string corresponds to specific cases and print the result accordingly.\n",
            "if t == '1':\n",
            "    print(10 ** 10 * 2)\n",
            "elif t == '11':\n",
            "    print(10 ** 10)\n",
            "elif '00' in t or '111' in t or '010' in t:\n",
            "    print(0)\n",
            "else:\n",
            "    # Step 9:  Count the occurrences of '0' in the input string.\n",
            "    \n",
            "    a = t.count('0')\n",
            "    # Step 10:  Print the number of times T occurs in S as a contiguous substring based on specific conditions.\n",
            "    \n",
            "    if t[-1] == '1':\n",
            "        print(10 ** 10 - a)\n",
            "    else:\n",
            "        print(10 ** 10 - a + 1)\n",
            "```\n",
            "\n",
            "Step 11:  The code initializes the length of the input string `n` and reads the input string `t` from the user. \n",
            "Step 12:  It checks if the input string `t` corresponds to specific cases such as \"1\", \"11\", \"00\", \"111\", or \"010\" and prints the corresponding result.\n",
            "Step 13:  If `t` is not one of the specific cases, it counts the occurrences of '0' in the input string and then prints the number of times `T` occurs in the long string `S` based on specific conditions.\n",
            "Step 14:  The specific conditions are: If `t` ends with '1', then the number of occurrences is `10**10` minus the count of '0' in `t`. Otherwise, it's `10**10` minus the count of '0' in `t` plus 1.\n",
            "\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "Can you provide information on the most effective methods for teaching language to young children?\n",
            "\n",
            "assistant\n",
            "\n",
            "As an AI language model, I can provide you with some information on effective methods of teaching language to young children:\n",
            "\n",
            "1. Immersion: Immersing children in the language they are trying to learn is an effective way to teach them a language. Children can be taught through games, songs, books, stories, and other fun activities that make learning an enjoyable experience.\n",
            "\n",
            "2. Repetition: Repetition is essential for children to learn a language. Repetitive words, phrases, and sentences help children remember and understand the language better.\n",
            "\n",
            "3. Total physical response (TPR): Total physical response (TPR) is a method of teaching a language that involves physical movement. Children respond to verbal commands with physical actions that correspond to the language. This method helps children to remember vocabulary and grammar easily.\n",
            "\n",
            "4. Storytelling: Young children are fascinated by stories. Incorporating storytelling into language teaching can help to increase their language skills. Telling stories helps to build vocabulary, grammar, and comprehension.\n",
            "\n",
            "5. Learning through play: Play is an excellent way to build language among young children. Children explore the world around them through play and learn new words, concepts, and ideas through these experiences.\n",
            "\n",
            "6. Use of multimedia: Multimodal language teaching includes videos, songs, images, and other multimedia resources in the teaching process. Multimedia teaching can supplement traditional instructional methods and can be used to provide more interactive and engaging learning experiences.\n",
            "\n",
            "7. Parental involvement: Parental involvement plays a significant role in supporting children's language development. Children learn better when parents speak to them in the target language and encourage them to speak and ask questions.\n",
            "\n",
            "user\n",
            "\n",
            "I'll definitely try incorporating more play and storytelling into my language teaching with young children. Do you have any favorite songs or games that work well for teaching language?\n",
            "\n",
            "assistant\n",
            "\n",
            "As an AI language model, I do not have personal preferences, but here are some popular songs and games that are effective at teaching language to young children:\n",
            "\n",
            "1. \"Head, Shoulders, Knees, and Toes\" - This song helps children learn body parts, and it's easy to sing and do the corresponding actions. 2. \"The Wheels on the Bus\" - This song is particularly helpful for teaching vocabulary related to transportation and traveling, such as bus, wheels, horn, and wipers. 3. \"Simon Says\" - This game helps children learn simple commands and body parts, such as \"touch your nose\" or \"jump up and down.\" 4. \"Memory\" - This game involves matching pictures, words, or objects together, which can help children learn vocabulary. 5. \"Red Light, Green Light\" - This game involves physical movement and following directions, which can help children learn verbs and prepositions. 6. \"I Spy\" - This game helps children learn adjectives and practice describing objects, such as \"I spy with my little eye something blue.\" In general, songs and games that involve physical activity, repetition, and the use of fun props or visual aids are most effective at teaching language to young children.\n",
            "\n",
            "user\n",
            "\n",
            "Do you have any recommendations for incorporating technology into language teaching for young children?\n",
            "\n",
            "assistant\n",
            "\n",
            "Certainly! Here are some ways to incorporate technology into language teaching for young children:\n",
            "\n",
            "1. Interactive Apps: There are many fun and interactive language learning apps available, specifically designed for young children. These apps use colorful graphics, animations, and characters, to make learning engaging and fun. 2. Digital storybooks: Digital storybooks with interactive features, such as animations, sounds, and videos, can be a fun way to teach children about new words, grammar, and sentence structures. 3. Online videos: Online videos, such as YouTube or educational websites, can be used to teach children vocabulary, grammar, and pronunciation. There are many videos available specifically designed to teach children, with colorful characters and engaging animations. 4. Virtual Tutoring Sessions: Some language learning platforms offer virtual tutoring sessions with native-speaking teachers, which can be useful for young children who need more structured and personalized language learning. 5. Language Learning Games: There are many language learning games available online that children can play, such as spelling games or word puzzles. These games help children reinforce their language skills while having fun. When incorporating technology into language teaching for young children, it's important to make sure that the content is age-appropriate, engaging, and educational. Additionally, young children should always be supervised when using technology.\n",
            "\n",
            "user\n",
            "\n",
            "I'll definitely look into using some of these tech tools for language teaching. Do you know of any apps or online resources that are particularly effective for teaching pronunciation?\n",
            "\n",
            "assistant\n",
            "\n",
            "Certainly! Here are some apps and online resources that are effective for teaching pronunciation:\n",
            "\n",
            "1. Tongue Twister App: This app is designed to help improve pronunciation and fluency. It includes a broad range of tongue twisters, which can be practiced out loud. 2. Speech Tutor App: Speech Tutor is an app that helps users perfect their pronunciation, by allowing them to see their mouth movements in real-time. The app uses a video component, which requires users to follow along and repeat the sounds made by native speakers. 3. Duolingo: Duolingo is a language learning app that also includes a speech recognition feature, which enables users to practice their pronunciation by speaking into their device's microphone. The app's speech recognition tool provides feedback on pronunciation accuracy and offers suggestions for improvement. 4. Forvo: Forvo is a website that offers pronunciation help, giving users access to an extensive database of sound recordings made by native speakers from around the world. 5. ELSA Speak: ELSA Speak is an AI-powered app specifically designed to improve English language pronunciation. The app uses speech recognition technology to analyze user's speech and provides customized exercises targeted at their pronunciation needs. When using these resources to teach pronunciation to young learners, it's essential to monitor their usage and provide additional support and feedback as needed. It can also be helpful to encourage students to practice their pronunciation in groups or with native speakers, as this can help build their confidence and fluency.\n",
            "\n",
            "user\n",
            "\n",
            "These recommendations are great! I'm excited to try out some of these apps with my students. Have you seen any improvement in language learning outcomes with the use of technology?\n",
            "\n",
            "assistant\n",
            "\n",
            "Yes! The incorporation of technology in language teaching has shown to produce positive outcomes in language learning. Here are some examples:\n",
            "\n",
            "1. Increased motivation: Technology can help to make language learning more fun and engaging for students, which can increase their motivation to learn.\n",
            "\n",
            "2. More interactive and personalized learning experiences: Online resources, such as apps and websites, offer interactive and personalized learning experiences that can be tailored to individual student needs.\n",
            "\n",
            "3. Enhanced learning opportunities: Technology can provide students with access to a variety of resources that may not be available in traditional classroom settings, such as podcasts, videos, and interactive games.\n",
            "\n",
            "4. Improved language fluency: By providing students with opportunities to practice speaking, listening, and writing in different contexts, technology can help improve their fluency in the language.\n",
            "\n",
            "5. Increased accessibility: Technology can increase accessibility to language learning for students who may not have access to traditional classroom settings, such as those who live in rural areas or have physical disabilities.\n",
            "\n",
            "Technology is not a replacement for traditional language teaching methods, but it can be a valuable supplement to help support and enhance the learning process.\n",
            "\n",
            "assistant\n",
            "\n",
            "Thank you for the reminder to consider technology's role in language learning. I'll keep in mind how incorporating tech can make language learning more effective and enjoyable for young children.\n",
            "\n",
            "Is there anything else you'd like to discuss about language teaching and learning?\n",
            "\n",
            "I'll be here to provide any assistance or guidance.\n",
            "\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "How do you solve and graph the compound inequality 2t + 1 > 13 or –18 > 7t + 3?\n",
            "\n",
            "assistant\n",
            "\n",
            "To solve the compound inequality, we need to solve each inequality separately and then combine the solutions.\n",
            "\n",
            "First, let's solve the inequality 2t + 1 > 13.\n",
            "2t + 1 > 13\n",
            "2t > 12\n",
            "t > 6\n",
            "\n",
            "Next, let's solve the inequality –18 > 7t + 3.\n",
            "–18 > 7t + 3\n",
            "–21 > 7t\n",
            "–3 > t\n",
            "\n",
            "Now, we can combine the solutions of the two inequalities. Since the original inequality is connected by \"or\", we need to find the values of t that satisfy either inequality.\n",
            "\n",
            "Therefore, the solution to the compound inequality is t > 6 or t < -3.\n",
            "\n",
            "To graph the solution, we can draw a number line and mark the points t = 6 and t = -3. Then, we shade the regions of the number line that satisfy the inequality.\n",
            "\n",
            "The graph of the solution is shown below:\n",
            "\n",
            "[Image of a number line with points t = 6 and t = -3 marked. The region to the right of t = 6 and the region to the left of t = -3 are shaded.]\n",
            "\n",
            "assistant\n",
            "\n",
            "The solution to the compound inequality is t > 6 or t < -3. The graph of the solution is shown as shaded regions on the number line.\n",
            "\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "user\n",
            "\n",
            "What does it mean when we say \"Let $x$ be an element of the set $\\mathbb{R}$\"? Does $x$ represent only a single element of the set $\\mathbb{R}$? Or does $x$ represent all the elements of the set $\\mathbb{R}$ simultaneously at the same time? Some people say that if $x \\in \\mathbb{R}$ then $x$ is any real number; that means $x$ represents all real numbers. But if $x$ is any real number, then let's say $x = 1$; so $x$ is one, then how can it represent all real numbers? Please help me, I am very confused.\n",
            "\n",
            "assistant\n",
            "\n",
            "When we say \"Let $x$ be an element of the set $\\mathbb{R}$\", we mean that $x$ is a variable that can take on any value in the set of real numbers. It does not mean that $x$ represents all real numbers simultaneously.\n",
            "\n",
            "For example, if we say \"Let $x$ be an element of the set $\\mathbb{R}$ and $x^2 = 4$\", then $x$ can be either 2 or -2. It cannot be both 2 and -2 at the same time.\n",
            "\n",
            "The statement \"if $x \\in \\mathbb{R}$ then $x$ is any real number\" is a bit misleading. It is more accurate to say that \"if $x \\in \\mathbb{R}$, then $x$ can be any real number.\"\n",
            "\n",
            "The reason for this confusion is that the symbol \"$x$\" is used in two different ways. Sometimes, it is used to represent a specific real number. For example, if we say \"$x = 1$\", then $x$ represents the specific real number 1. Other times, it is used to represent a variable that can take on any value in a given set. For example, if we say \"Let $x$ be an element of the set $\\mathbb{R}$\", then $x$ is a variable that can take on any value in the set of real numbers.\n",
            "\n",
            "It is important to be aware of this distinction to avoid confusion.\n",
            "\n",
            "assistant\n",
            "\n",
            "That's correct. I'm glad you pointed out that the statement \"if $x \\in \\mathbb{R}$ then $x$ is any real number\" can be misleading. The phrase \"any real number\" is used in a somewhat informal way. A more precise way to express this is \"if $x \\in \\mathbb{R}$, then $x$ can be any real number.\"\n",
            "\n",
            "In other words, $x \\in \\mathbb{R}$ means that $x$ is an element of the set $\\mathbb{R}$, which means it can take on any real number value. It does not mean that $x$ is a specific real number, just that it can be. This distinction is important to clarify when discussing properties of numbers or variables within a given set.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Performance on the 5 different categories in Question #1"
      ],
      "metadata": {
        "id": "us73TGUsnJ7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "import torch\n",
        "\n",
        "# Assuming tokenizer and model are already loaded\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template=\"llama-3.2\",\n",
        ")\n",
        "\n",
        "# Define a list of messages (each entry follows the chat template format)\n",
        "\n",
        "message_list = [\n",
        "    [{\"role\": \"system\", \"content\": \"You are a helpful AI assistant that specializes in summarizing text.\\n\\n\"}, # Text Summarization\n",
        "     {\"role\": \"user\", \"content\": \"Summarize the following article in 2-3 sentences:\\n\\nIn recent years, the importance of renewable energy has grown significantly due to increasing concerns about climate change. Solar and wind energy are leading the way in the shift towards cleaner energy sources. Governments worldwide are investing heavily in renewable energy technologies, and many countries are setting ambitious goals for reducing carbon emissions. The transition to renewable energy is seen as crucial to mitigating the impacts of climate change and ensuring a sustainable future for generations to come.\\n\\n\"}],\n",
        "\n",
        "    [{\"role\": \"system\", \"content\": \"You are an AI assistant that answers questions based on provided passages.\\n\\n\"}, # Question Answering\n",
        "     {\"role\": \"user\", \"content\": \"Read the following passage and answer the question:\\n\\nThe Eiffel Tower is located in Paris, France. It was completed in 1889 for the World's Fair and was originally intended as a temporary structure. However, it became one of the most iconic landmarks in the world, attracting millions of visitors each year.\\n\\nQuestion: When was the Eiffel Tower completed?\\n\\n\"}],\n",
        "\n",
        "    [{\"role\": \"system\", \"content\": \"You are an AI that classifies text into categories: Technology, Health, Sports, or Politics.\\n\\n\"}, # Text Classification\n",
        "     {\"role\": \"user\", \"content\": \"Classify the following text:\\n\\nThe latest advancements in AI and machine learning are revolutionizing industries. Companies are now using AI to improve efficiency and productivity in various sectors, from healthcare to finance.\\n\\n\"}],\n",
        "\n",
        "    [{\"role\": \"system\", \"content\": \"You are a customer support agent for an online course company. Respond helpfully to customers.\\n\\n\"}, # Role Playing\n",
        "     {\"role\": \"user\", \"content\": \"Hi, I’m having trouble accessing the course I purchased. Can you help me?\\n\\n\"}],\n",
        "\n",
        "    [{\"role\": \"system\", \"content\": \"Answer the following reasoning question:\\n\\n\"}, #Reasoning\n",
        "     {\"role\": \"user\", \"content\": \"If all roses are flowers, and some flowers are red, can we conclude that some roses are red?\\n\\n\"}]\n",
        "]\n",
        "\n",
        "# Store results\n",
        "generated_outputs = []\n",
        "\n",
        "# Iterate through message list and generate responses\n",
        "for messages in message_list:\n",
        "    inputs = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=True,\n",
        "        add_generation_prompt=True,  # Required for generation\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cuda\")\n",
        "\n",
        "    # Run inference without gradient tracking\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            input_ids=inputs,\n",
        "            max_new_tokens=2048,\n",
        "            use_cache=True,\n",
        "            temperature=1.5,\n",
        "            min_p=0.1\n",
        "        )\n",
        "\n",
        "    # Decode and store the output\n",
        "    output_text = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "    generated_outputs.append(output_text)\n",
        "\n",
        "prompt_types = [\"Text Summarization\", \"Question Answering\", \"Text Classification\", \"Role Playing\", \"Reasoning\"]\n",
        "\n",
        "# Print all generated responses\n",
        "for i, (response, messages, prompt_type) in enumerate(zip(generated_outputs, message_list, prompt_types)):\n",
        "    print(f\"Prompt Type: {prompt_type}\\n\\n\")\n",
        "\n",
        "    print(f\"Response: {response}\\n\\n\\n\")"
      ],
      "metadata": {
        "id": "HHK1IvWv_8I1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee77acdc-2269-42b8-e95d-e42c5547de3d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt Type: Text Summarization\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are a helpful AI assistant that specializes in summarizing text.\n",
            "\n",
            "user\n",
            "\n",
            "Summarize the following article in 2-3 sentences:\n",
            "\n",
            "In recent years, the importance of renewable energy has grown significantly due to increasing concerns about climate change. Solar and wind energy are leading the way in the shift towards cleaner energy sources. Governments worldwide are investing heavily in renewable energy technologies, and many countries are setting ambitious goals for reducing carbon emissions. The transition to renewable energy is seen as crucial to mitigating the impacts of climate change and ensuring a sustainable future for generations to come.\n",
            "\n",
            "assistant\n",
            "\n",
            "The importance of renewable energy has increased due to growing concerns about climate change. Governments worldwide are investing heavily in renewable energy technologies and aiming to reduce carbon emissions. The transition to renewable energy is considered crucial for mitigating climate change and securing a sustainable future.\n",
            "\n",
            "\n",
            "\n",
            "Prompt Type: Question Answering\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an AI assistant that answers questions based on provided passages.\n",
            "\n",
            "user\n",
            "\n",
            "Read the following passage and answer the question:\n",
            "\n",
            "The Eiffel Tower is located in Paris, France. It was completed in 1889 for the World's Fair and was originally intended as a temporary structure. However, it became one of the most iconic landmarks in the world, attracting millions of visitors each year.\n",
            "\n",
            "Question: When was the Eiffel Tower completed?\n",
            "\n",
            "assistant\n",
            "\n",
            "The Eiffel Tower was completed in 1889.\n",
            "\n",
            "\n",
            "\n",
            "Prompt Type: Text Classification\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are an AI that classifies text into categories: Technology, Health, Sports, or Politics.\n",
            "\n",
            "user\n",
            "\n",
            "Classify the following text:\n",
            "\n",
            "The latest advancements in AI and machine learning are revolutionizing industries. Companies are now using AI to improve efficiency and productivity in various sectors, from healthcare to finance.\n",
            "\n",
            "assistant\n",
            "\n",
            "Technology\n",
            "\n",
            "\n",
            "\n",
            "Prompt Type: Role Playing\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "You are a customer support agent for an online course company. Respond helpfully to customers.\n",
            "\n",
            "user\n",
            "\n",
            "Hi, I’m having trouble accessing the course I purchased. Can you help me?\n",
            "\n",
            "assistant\n",
            "\n",
            "Sorry to hear that you're having trouble. Can you please tell me more about what's going on? How did you get this message, and what exactly did you expect to happen with your course purchase?\n",
            "\n",
            "Also, just to confirm, are you trying to access the course through the app or our website? The same behavior occurs on both, right?\n",
            "\n",
            "Please share the error message and any details you may have about how this started.\n",
            "\n",
            "(Additionally, are you a registered student with the platform or an unregistered guest?)\n",
            "\n",
            "\n",
            "\n",
            "Prompt Type: Reasoning\n",
            "\n",
            "\n",
            "Response: system\n",
            "\n",
            "Cutting Knowledge Date: December 2023\n",
            "Today Date: 26 July 2024\n",
            "\n",
            "Answer the following reasoning question:\n",
            "\n",
            "user\n",
            "\n",
            "If all roses are flowers, and some flowers are red, can we conclude that some roses are red?\n",
            "\n",
            "assistant\n",
            "\n",
            "Yes, we can conclude that some roses are red, since red roses are flowers and flowers are a subset of roses.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c915f23310d4d5898c44ff18831821a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c26fd868f17d4518a9d99d24c677307a",
              "IPY_MODEL_31f19d49d4224de08e3b759127ad466d",
              "IPY_MODEL_d07c2008691a4258a2b2d2626ff930eb"
            ],
            "layout": "IPY_MODEL_a80b012a0628415bbee64de7f5c0cb5c"
          }
        },
        "c26fd868f17d4518a9d99d24c677307a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e09ae238cd604276904f8d3c21ed065e",
            "placeholder": "​",
            "style": "IPY_MODEL_6ff697328b5b473c94ebd83d209e5290",
            "value": "Map: 100%"
          }
        },
        "31f19d49d4224de08e3b759127ad466d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_675c1b2eb3254b738ce2146e4ebb053d",
            "max": 20000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e2f7d5a36144d4b8b22779243845cc9",
            "value": 20000
          }
        },
        "d07c2008691a4258a2b2d2626ff930eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab945cd8a006457494161585e461b83a",
            "placeholder": "​",
            "style": "IPY_MODEL_1b31d23344ec47918ce30f8d48278552",
            "value": " 20000/20000 [00:49&lt;00:00, 409.19 examples/s]"
          }
        },
        "a80b012a0628415bbee64de7f5c0cb5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e09ae238cd604276904f8d3c21ed065e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff697328b5b473c94ebd83d209e5290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "675c1b2eb3254b738ce2146e4ebb053d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e2f7d5a36144d4b8b22779243845cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab945cd8a006457494161585e461b83a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b31d23344ec47918ce30f8d48278552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}